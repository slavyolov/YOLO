# YOLO
Object detection using YOLO algorithm

URL  | description | takeaways | 
:---:|:---         |:---     |
Yolo v4, v3 and v2 for Windows and Linux (https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects) | DarkNet framework - open-source Neural Network in C
YOLO v3 Object Detection with Keras (https://towardsdatascience.com/yolo-v3-object-detection-with-keras-461d2cfccef6) | Description of the YOLO v3 algorithm | - The output of the YOLO v3 prediction is in the form of a list of arrays. As YOLO v3 is a multi-scale detection, it is decoded into three different scales in the shape of (13, 13, 225), (26, 26, 225), and (52, 52, 225). <br><br> - Non-Max Suppression (NMS) takes place to filter out in order to get the correct boxes.<br/><br/> - IOU (intersection over Union)<br/>
YOLO v3 paper (https://pjreddie.com/media/files/papers/YOLOv3.pdf)| Description of the YOLO v3 algorithm | - **Bounding Box Prediction :** <br><br>YOLOv3 predicts an objectness score for each boundingbox using logistic regression. This should be 1 if the bound-ing box prior overlaps a ground truth object by more than any  other  bounding  box  prior. <br><br>- **Class prediction** :<br><br> Each box predicts the classes the bounding box may contain using multilabel classification. We do not use a softmaxas we have found it is unnecessary for good performance,instead we simply use independent logistic classifiers. During training we use binary cross-entropy loss for the class predictions. <br><br>Using a softmax imposes the assumption that each box has exactly one class which is often not the case.  A multilabel approach better models the data. <br><br>- **Prediction Across Scales :** <br><br> YOLOv3 predicts boxes at 3 different scales. <br><br> We  just  sort  of  chose  9  clusters  and  3scales  arbitrarily  and  then  divide  up  the  clusters  evenlyacross scales. **These are the 'anchors'** <br/><br/>- **Feature Extractor :** <br/><br/> Our network uses successive 3×3 and 1×1 convolutional layers but now has some shortcut connections as well and is significantly larger.  It has 53 convolutional layers so we call it **Darknet-53** <br/><br/> - **NOTE :** <br/><br/> In the past YOLO struggled with small objects.  However,  now  we  see  a  reversal  in  that  trend.   With  the  new multi-scale predictions we see YOLOv3 has relatively high APs performance. However, **it  has  comparatively  worse performance on medium and larger size objects**
YOLO: Real-Time Object Detection (https://pjreddie.com/darknet/yolo/)| |
Understanding YOLO (https://hackernoon.com/understanding-yolo-f5a74bbc7967)| |- So, to put it simple, you take an image as input, pass it through a neural network that looks similar to a normal CNN, and you get a vector of bounding boxes and class predictions in the output. <br/><br/> -  **The Prediction Vector :** <br/><br/> The first step to understanding YOLO is how it encodes its output. The input image is divided into an S x S grid of cells. For each object that is present on the image, one grid cell is said to be “responsible” for predicting it. That is the cell where the center of the object falls into. <br/><br/> Each grid cell predicts B bounding boxes as well as C class probabilities. The bounding box prediction has 5 components: (x, y, w, h, confidence). The (x, y) coordinates represent the center of the box, relative to the grid cell location (remember that, if the center of the box does not fall inside the grid cell, than this cell is not responsible for it). These coordinates are normalized to fall between 0 and 1. The (w, h) box dimensions are also normalized to [0, 1], relative to the image size. **Let’s look at an example: !!!see the article!!!**
Intersection over Union (IoU) for object detection (https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)| evaluation metric | An Intersection over Union score > 0.5 is normally considered a “good” prediction.  
image size (32x32x3 (32 wide, 32 high, 3 color channels - e.g. RGB))| | 
Convolutional Neural Networks (CNNs / ConvNets) (https://cs231n.github.io/convolutional-networks/)| | - Regular Neural Nets don’t scale well to full images. In CIFAR-10, images are only of size 32x32x3 (32 wide, 32 high, 3 color channels), so a single fully-connected neuron in a first hidden layer of a regular Neural Network would have 32*32*3 = 3072 weights. **read more in the article** <br/><br/> -3D volumes of neurons. Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth. **read more in the article** <br/><br/> -**Layers used to build ConvNets** Convolutional Layer, Pooling Layer, and Fully-Connected Layer (exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture. **read more in the article** <br/><br/> - Live running neural network: http://cs231n.stanford.edu/
Gradient descent (https://en.wikipedia.org/wiki/Gradient_descent) | |
Anchor Boxes (https://www.youtube.com/watch?v=RTlwl2bv0Tg) | |
The beginner’s guide to implementing YOLOv3 in TensorFlow 2.0 (part-1) (https://machinelearningspace.com/yolov3-tensorflow-2-part-1/) | |  YOLOv3 predicts over 3 different scales detection, so if we feed an image of size 416x 416, it produces 3 different output shape tensor, 13 x 13 x 255, 26 x 26 x 255, and 52 x 52 x 255 <br/><br/>- YOLO applies a single neural network to the whole image and predicts the bounding boxes and class probabilities as well. This makes YOLO a super-fast real-time object detection algorithm.<br/> <br/><br/>- YOLO divides an image into SxS grid cells. Every cell is responsible for detecting an object whose center falls inside.<br/> <br/><br/>- To overcome the overlapping objects whose centers fall in the same grid cell, YOLOv3 uses anchor boxes.<br/> <br/><br/>- To facilitate the prediction across scale, YOLOv3 uses three different numbers of grid cell sizes (13×13), (26×26), and (52×52).<br/> <br/><br/>- A Non-Max Suppression is used to eliminate the overlapping boxes and keep only the accurate one.<br/> 
What’s new in YOLO v3? (https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b) | | Larger input resolutions don’t help much in our case, but they might help in detection of images with small objects. On the other hand, larger input resolutions add to inference time. This is a hyper parameter that needs to be tuned depending upon application. <br/><br/>You can experiment with other metrics such as batch size, objectness confidence, and NMS threshold by going to the repo. <br/><br/> 
How to Train YOLOv4 on a Custom Dataset (https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/) | | 
A Gentle Introduction to YOLO v4 for Object detection in Ubuntu 20.04 (https://robocademy.com/2020/05/01/a-gentle-introduction-to-yolo-v4-for-object-detection-in-ubuntu-20-04/) | | List difference of the different YOLO versions + how to setup and run
How to Train Scaled-YOLOv4 to Detect Custom Objects (https://towardsdatascience.com/how-to-train-scaled-yolov4-to-detect-custom-objects-13f9077ebc89) | |
YOLOv4 Tutorial #1  Prerequisites for YOLOv4 Installation in 10 Steps (https://augmentedstartups.medium.com/yolov4-tutorial-1-prerequisites-for-yolov4-installation-in-10-steps-6e7ef571cf4b) | |
Train your own YOLO v3 (https://github.com/AntonMu/TrainYourOwnYOLO) | | 
